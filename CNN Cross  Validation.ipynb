{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "BestScore.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WxX_LQ0naSy0",
        "colab_type": "text"
      },
      "source": [
        "Interesting paper https://reader.elsevier.com/reader/sd/pii/S1877050917316599?token=63147E6FB36A421DB648052F0A734C07182BF929F1E6FE4F62F2F0CA6A280FAE311F85835C9CC3F188C17B1458D1A80D"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ed3wu1b_abi1",
        "colab_type": "code",
        "outputId": "eb4e2cc8-1172-4524-cdcb-04b209b158a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "# getting the data\n",
        "!git clone https://mihainsto:0dabea4eb5ec4a2ec6feff5cdbb6a9837fa0c342@github.com/mihainsto/Surgical-Mask-Audio-ML.git"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Surgical-Mask-Audio-ML'...\n",
            "remote: Enumerating objects: 145951, done.\u001b[K\n",
            "remote: Total 145951 (delta 0), reused 0 (delta 0), pack-reused 145951\u001b[K\n",
            "Receiving objects: 100% (145951/145951), 2.92 GiB | 41.02 MiB/s, done.\n",
            "Resolving deltas: 100% (71/71), done.\n",
            "Checking out files: 100% (92013/92013), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aXgyp-GG4CcN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -rf \"Surgical-Mask-Audio-ML/validation\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4LkuM62I34xT",
        "colab_type": "code",
        "outputId": "24f67ad2-eb86-4919-9d1d-e88c8aa5c3ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mEoDLnSyAXr4",
        "colab_type": "code",
        "outputId": "a14a357a-d11a-44e6-e88b-9117607f2971",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "!ls \"/content/gdrive/My Drive/ML/Surgical Mask/70acccrossold/\"\n",
        "!ls \"/content/gdrive/My Drive/ML/Surgical Mask/70acccrossnew\"\n",
        "\n",
        "drive_link = \"/content/gdrive/My Drive/ML/Surgical Mask/70acccrossold/\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "modelfold1.hdf5  modelfold3.hdf5  modelfold5.hdf5  submisieCross.txt\n",
            "modelfold2.hdf5  modelfold4.hdf5  modelfold6.hdf5\n",
            "modelfold1.hdf5  modelfold3.hdf5  modelfold5.hdf5  modelfold7.hdf5\n",
            "modelfold2.hdf5  modelfold4.hdf5  modelfold6.hdf5  modelfold8.hdf5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "nxfm4F__aSy2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "import IPython.display as ipd # to display audio inside jupyter\n",
        "#import librosa # Audio parsing\n",
        "#import librosa.display\n",
        "import matplotlib.pyplot as plt # to make graphs\n",
        "import sklearn # Ml\n",
        "from tqdm import tqdm_notebook as tqdm # progress bar\n",
        "import multiprocessing # going faster\n",
        "from multiprocessing import Pool\n",
        "import time\n",
        "import glob\n",
        "import gc\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras.preprocessing.image import array_to_img\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "# for dirname, _, filenames in os.walk('/kaggle/input/surgical-mask-create-images/train/fold_spectogram/images'):\n",
        "#     for filename in filenames:\n",
        "#         print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "GWtY6pJwaSy7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "images_input =  \"surgical-mask-create-images\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "trusted": true,
        "id": "u3M9fxfdaSzA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# reading competition data\n",
        "def f_path(fileName, tpe = None):\n",
        "    \"\"\"\n",
        "    Adds full path to a filename recived\n",
        "    tpe = None / validation / train / test\n",
        "    \"\"\"\n",
        "    if tpe == None:\n",
        "        return \"Surgical-Mask-Audio-ML/ml-fmi-23-2020/\" + fileName\n",
        "    else:\n",
        "        return \"Surgical-Mask-Audio-ML/ml-fmi-23-2020/\" + tpe + \"/\" + tpe + \"/\" + fileName\n",
        "    \n",
        "def split_into_files(file):\n",
        "    \"\"\"\n",
        "    Splits the recived input into files\n",
        "    \"\"\"\n",
        "    file = file.split(\"\\n\")\n",
        "    file = [x.split(\",\") for x in file]\n",
        "    return file\n",
        "# Reading the file names\n",
        "with open(f_path(\"train.txt\"), \"r\") as f:\n",
        "    trainFileNames = split_into_files(f.read())\n",
        "with open(f_path(\"validation.txt\"), \"r\") as f:\n",
        "    validationFileNames = split_into_files(f.read())\n",
        "with open(f_path(\"test.txt\"), \"r\") as f:\n",
        "    testFileNames = split_into_files(f.read())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "ljK0rBwqaSzD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Reading competition data\n",
        "trainFileNames = trainFileNames[:-1]\n",
        "trainOnlyFilesNames = [x[0] for x in trainFileNames]\n",
        "trainLabels = [int(x[1]) for x in trainFileNames]\n",
        "\n",
        "validationFileNames = validationFileNames[:-1]\n",
        "validationOnlyFilesNames = [x[0] for x in validationFileNames]\n",
        "validationLabels = [int(x[1]) for x in validationFileNames]\n",
        "\n",
        "testFileNames = testFileNames[:-1]\n",
        "testOnlyFilesNames = [x[0] for x in validationFileNames]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Wk-67Rb8aSzG",
        "colab_type": "code",
        "outputId": "705309f6-48c1-4e54-94ef-2af75b77b001",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "def read_images_from_dir(directory):\n",
        "    files = glob.glob(directory + \"/*\")\n",
        "    print(directory)\n",
        "    #images = [load_img(x) for x in files]\n",
        "    images = [load_img(x, grayscale=True) for x in files]\n",
        "    filesId = [x.split('/')[-1].split('.')[0] for x in files]\n",
        "    \n",
        "    return images, filesId\n",
        "\n",
        "def read_all_images_for(dataType, spectogramType):\n",
        "    \"\"\"\n",
        "    spectogramTypes = fold_spectogram / mfcc_spectogram / crf_spectogram\n",
        "    \n",
        "    \"\"\"\n",
        "    spectogramDir = \"Surgical-Mask-Audio-ML/\"+dataType+\"/\"+spectogramType+\"/images\"\n",
        "    if dataType == \"validation\":\n",
        "      spectogramDir = \"Surgical-Mask-Audio-ML/kfold/\"+dataType+\"/\"+spectogramType+\"/images\"\n",
        "      \n",
        "    spectogram = read_images_from_dir(spectogramDir) \n",
        "    return spectogram\n",
        "    \n",
        "# Reading image data\n",
        "\n",
        "trainDir = \"Surgical-Mask-Audio-ML/train\"\n",
        "validationDir = \"Surgical-Mask-Audio-ML/kfold/validation\"\n",
        "testDir = \"Surgical-Mask-Audio-ML/test\"\n",
        "\n",
        "test_fold_spectogram = read_all_images_for(\"test\", \"fold_spectogram\")\n",
        "# test_mfcc_spectogram = read_all_images_for(\"test\", \"mfcc_spectogram\")\n",
        "# test_crf_spectogram = read_all_images_for(\"test\", \"crf_spectogram\")\n",
        "\n",
        "train_fold_spectogram = read_all_images_for(\"train\", \"fold_spectogram\")\n",
        "# train_mfcc_spectogram = read_all_images_for(\"train\", \"mfcc_spectogram\")\n",
        "# train_crf_spectogram = read_all_images_for(\"train\", \"crf_spectogram\")\n",
        "\n",
        "validation_fold_spectogram = read_all_images_for(\"validation\", \"fold_spectogram\")\n",
        "# validation_mfcc_spectogram = read_all_images_for(\"validation\", \"mfcc_spectogram\")\n",
        "# validation_crf_spectogram = read_all_images_for(\"validation\", \"crf_spectogram\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Surgical-Mask-Audio-ML/test/fold_spectogram/images\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/utils.py:107: UserWarning: grayscale is deprecated. Please use color_mode = \"grayscale\"\n",
            "  warnings.warn('grayscale is deprecated. Please use '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Surgical-Mask-Audio-ML/train/fold_spectogram/images\n",
            "Surgical-Mask-Audio-ML/kfold/validation/fold_spectogram/images\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "hsFwd325aSzW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Gg8md2skaSzc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DataGenerator(keras.utils.Sequence):\n",
        "    def __image_processing(self, image):\n",
        "        image_ar = img_to_array(image)\n",
        "        return image_ar\n",
        "        #return np.concatenate((img_to_array(image[0]), img_to_array(image[1]), img_to_array(image[2])), axis = 2) # for 3 images in one\n",
        "    def __get_label_from_aid(self,aid):\n",
        "        aid = aid.replace('a', '')\n",
        "        try:\n",
        "            index = trainOnlyFilesNames.index(str(aid) + \".wav\")\n",
        "            return trainLabels[index]\n",
        "        except:\n",
        "            pass\n",
        "        try:\n",
        "            index = validationOnlyFilesNames.index(str(aid) + \".wav\")\n",
        "            return validationLabels[index]\n",
        "        except:\n",
        "            pass\n",
        "        return -1\n",
        "    def __split_image_list_into_labels(self, list_images):\n",
        "        images = []\n",
        "        for i in range(len(list_images[0])):\n",
        "            images.append(\n",
        "                (list_images[0][i], list_images[1][i]))   \n",
        "        return images\n",
        "    \n",
        "    def __init__(self, list_images, batch_size=32, dim=(32, 32, 32), n_channels=1,\n",
        "                 n_classes=2, shuffle=True, augment=False):\n",
        "        'Initialization'\n",
        "        self.dim = dim\n",
        "        self.batch_size = batch_size\n",
        "        self.list_images = self.__split_image_list_into_labels(list_images)\n",
        "        self.n_channels = n_channels\n",
        "        self.n_classes = n_classes\n",
        "        self.shuffle = shuffle\n",
        "        self.augment = augment\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        'Updates indexes after each epoch'\n",
        "        self.indexes = np.arange(len(self.list_images))\n",
        "        if self.shuffle == True:\n",
        "            np.random.shuffle(self.indexes)\n",
        "\n",
        "    def __data_generation(self, list_images_temp):\n",
        "        # X : (n_samples, *dim, n_channels)\n",
        "        'Generates data containing batch_size samples'\n",
        "        # Initialization\n",
        "        #X = np.empty((self.batch_size, *self.dim, self.n_channels))\n",
        "        #y = np.empty((self.batch_size), dtype=int)\n",
        "        X = [0] * self.batch_size\n",
        "        y = [0] * self.batch_size\n",
        "        # Generate data\n",
        "        for i, images in enumerate(list_images_temp):\n",
        "            # Store sample\n",
        "            X[i] = self.__image_processing(images[0])\n",
        "            # Store class\n",
        "            y[i] = self.__get_label_from_aid(images[1])\n",
        "        \n",
        "        X = np.asarray(X)\n",
        "        y = np.asarray(y)\n",
        "        return X, y\n",
        "\n",
        "    def __len__(self):\n",
        "        'Denotes the number of batches per epoch'\n",
        "        return int(np.floor(len(self.list_images) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        'Generate one batch of data'\n",
        "        # Generate indexes of the batch\n",
        "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
        "\n",
        "        # Find list of images\n",
        "        list_images_temp = [self.list_images[k] for k in indexes]\n",
        "\n",
        "        # Generate data\n",
        "        X, y = self.__data_generation(list_images_temp)\n",
        "\n",
        "        return X, y\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "wbtWXZqMaSzf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_label_from_aid(aid):\n",
        "    aid = aid.replace('a', '')\n",
        "    try:\n",
        "        index = trainOnlyFilesNames.index(str(aid) + \".wav\")\n",
        "        return trainLabels[index]\n",
        "    except:\n",
        "        pass\n",
        "    try:\n",
        "        index = validationOnlyFilesNames.index(str(aid) + \".wav\")\n",
        "        return validationLabels[index]\n",
        "    except:\n",
        "        pass\n",
        "    return -1\n",
        "\n",
        "def preproces_images(images):\n",
        "    newImages = [img_to_array(x) for x in images]\n",
        "    return newImages\n",
        "\n",
        "def generate_data_and_labels(data):\n",
        "    images, fileNames = data\n",
        "    \n",
        "    X = preproces_images(images)\n",
        "    Y = [get_label_from_aid(x) for x in fileNames]\n",
        "    \n",
        "    return X, Y\n",
        "\n",
        "def generate_labels(data):\n",
        "    images, fileNames = data\n",
        "    \n",
        "    Y = [get_label_from_aid(x) for x in fileNames]\n",
        "    \n",
        "    return Y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "6J0lMAsNaSzm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_validation, Y_validation = generate_data_and_labels(validation_fold_spectogram)\n",
        "X_test = np.array(generate_data_and_labels(test_fold_spectogram)[0])\n",
        "X_validation = np.asarray(X_validation)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "PtI0_nhCaSzp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y_train = generate_labels(train_fold_spectogram)\n",
        "Y_train = np.asarray(Y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "1mK3jZoXaSzu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_generator = DataGenerator(train_fold_spectogram)\n",
        "validation_generator = DataGenerator(validation_fold_spectogram)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Lge960kCaSz0",
        "colab_type": "code",
        "outputId": "9ef3d0d5-8867-4804-fe2f-ea498faba5ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, InputLayer, LSTM, Bidirectional, GlobalMaxPooling1D, Conv2D, Dropout, MaxPooling2D,Input,ThresholdedReLU, Flatten, BatchNormalization, Activation, GlobalMaxPooling2D, concatenate, GlobalAveragePooling2D, AveragePooling2D\n",
        "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, CSVLogger, Callback, EarlyStopping\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, CSVLogger, Callback, EarlyStopping\n",
        "import sklearn\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "spSZIZd1HYxM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#CROSS VALIDATION"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "_-4UvBYIaS0D",
        "colab_type": "code",
        "outputId": "31bd2d8a-3731-4a69-a46e-afedce11d880",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_full = ([],[])\n",
        "\n",
        "for i in range(len(train_fold_spectogram[1])):\n",
        "  X_full[0].append(train_fold_spectogram[0][i])\n",
        "  X_full[1].append(train_fold_spectogram[1][i])\n",
        "\n",
        "for i in range(len(validation_fold_spectogram[1])):\n",
        "  X_full[0].append(validation_fold_spectogram[0][i])\n",
        "  X_full[1].append(validation_fold_spectogram[1][i])\n",
        "\n",
        "Y_full = []\n",
        "for i in range(len(Y_train)):\n",
        "  Y_full.append(Y_train[i])\n",
        "for i in range(len(Y_validation)):\n",
        "  Y_full.append(Y_validation[i])\n",
        "print(str(len(Y_full)) + \" samples\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "36000 samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "vXKWFGH9aS0F",
        "colab_type": "code",
        "outputId": "a116321c-74c3-40b7-9f60-c95a03e019f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "def create_model():\n",
        "    main_input = Input(shape = (221, 223, 1))\n",
        "    x = Conv2D(32, (3, 3), kernel_initializer='he_uniform', padding='same')(main_input)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    x = Conv2D(32, (3, 3), kernel_initializer='he_uniform', padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    x = Conv2D(32, (3, 3), kernel_initializer='he_uniform', padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    x = MaxPooling2D((2,2))(x)\n",
        "\n",
        "    x = Conv2D(64, (3, 3), kernel_initializer='he_uniform', padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    x = Conv2D(64, (3, 3), kernel_initializer='he_uniform', padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    x = Conv2D(64, (3, 3), kernel_initializer='he_uniform', padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    x = MaxPooling2D((3,3))(x)\n",
        "\n",
        "    x = Conv2D(128, (3, 3), kernel_initializer='he_uniform', padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    x = Conv2D(128, (3, 3), kernel_initializer='he_uniform', padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    x = Conv2D(128, (3, 3), kernel_initializer='he_uniform', padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    x = MaxPooling2D((2,2))(x)\n",
        "    x = Flatten()(x)\n",
        "\n",
        "    x = Dense(128, activation='relu', kernel_initializer='he_uniform')(x)\n",
        "    x = Dense(64, activation='relu', kernel_initializer='he_uniform')(x)\n",
        "    output = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "    model = Model(inputs=main_input, outputs=output)\n",
        "    model.compile(optimizer=\"adam\", loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "\n",
        "\n",
        "curentFold = 0\n",
        "kf = KFold(n_splits=10, shuffle = True, random_state = 42)\n",
        "for train_index, test_index in kf.split(X_full[1]):\n",
        "    curentFold += 1\n",
        "    print(\"Starting Fold \"+str(curentFold))\n",
        "    gc.collect()\n",
        "    X_train_fold = ([], [])\n",
        "    X_test_fold = ([], [])\n",
        "\n",
        "    for index in train_index:\n",
        "      X_train_fold[0].append(X_full[0][index])\n",
        "      X_train_fold[1].append(X_full[1][index])\n",
        "    for index in test_index:\n",
        "      X_test_fold[0].append(X_full[0][index])\n",
        "      X_test_fold[1].append(X_full[1][index])\n",
        "\n",
        "    Y_train_fold = np.array([Y_full[x] for x in train_index])\n",
        "    Y_test_fold = np.array([Y_full[x] for x in test_index])\n",
        "    \n",
        "    train_generator = DataGenerator(X_train_fold)\n",
        "    validation_generator = DataGenerator(X_test_fold)\n",
        "    \n",
        "    class_weight = sklearn.utils.class_weight.compute_class_weight('balanced',np.unique(Y_train_fold), Y_train_fold)\n",
        "    class_weight = {i : class_weight[i] for i in range(2)}\n",
        "\n",
        "    model=create_model()\n",
        "    mcp_save = ModelCheckpoint('modelfold'+str(curentFold)+'.hdf5', save_best_only=True, monitor='val_loss', mode='min')\n",
        "    mcp_save_drive = ModelCheckpoint(drive_link+'modelfold'+str(curentFold)+'.hdf5', save_best_only=True, monitor='val_loss', mode='min')\n",
        "\n",
        "\n",
        "    model.fit(x = train_generator, epochs = 200, validation_data=validation_generator, shuffle=True,\n",
        "                         class_weight = class_weight, \n",
        "                callbacks= [\n",
        "                              EarlyStopping(patience=10, monitor='val_loss', mode='min'),\n",
        "                              mcp_save,\n",
        "                              mcp_save_drive,\n",
        "                              ReduceLROnPlateau(factor=.3)\n",
        "                         ])\n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting Fold 1\n",
            "Starting Fold 2\n",
            "Starting Fold 3\n",
            "Starting Fold 4\n",
            "Starting Fold 5\n",
            "Starting Fold 6\n",
            "Epoch 1/200\n",
            "1012/1012 [==============================] - 128s 127ms/step - loss: 0.7914 - accuracy: 0.5605 - val_loss: 0.6608 - val_accuracy: 0.6127 - lr: 0.0010\n",
            "Epoch 2/200\n",
            "1012/1012 [==============================] - 128s 126ms/step - loss: 0.5958 - accuracy: 0.6743 - val_loss: 0.5323 - val_accuracy: 0.7313 - lr: 0.0010\n",
            "Epoch 3/200\n",
            "1012/1012 [==============================] - 128s 126ms/step - loss: 0.4959 - accuracy: 0.7536 - val_loss: 0.4509 - val_accuracy: 0.7846 - lr: 0.0010\n",
            "Epoch 4/200\n",
            "1012/1012 [==============================] - 128s 126ms/step - loss: 0.3976 - accuracy: 0.8189 - val_loss: 0.3733 - val_accuracy: 0.8396 - lr: 0.0010\n",
            "Epoch 5/200\n",
            "1012/1012 [==============================] - 128s 127ms/step - loss: 0.2839 - accuracy: 0.8803 - val_loss: 0.3100 - val_accuracy: 0.8714 - lr: 0.0010\n",
            "Epoch 6/200\n",
            "1012/1012 [==============================] - 128s 126ms/step - loss: 0.1804 - accuracy: 0.9288 - val_loss: 0.1825 - val_accuracy: 0.9289 - lr: 0.0010\n",
            "Epoch 7/200\n",
            "1012/1012 [==============================] - 127s 125ms/step - loss: 0.1178 - accuracy: 0.9557 - val_loss: 0.1944 - val_accuracy: 0.9308 - lr: 0.0010\n",
            "Epoch 8/200\n",
            "1012/1012 [==============================] - 128s 126ms/step - loss: 0.0821 - accuracy: 0.9690 - val_loss: 0.1301 - val_accuracy: 0.9509 - lr: 0.0010\n",
            "Epoch 9/200\n",
            "1012/1012 [==============================] - 127s 125ms/step - loss: 0.0633 - accuracy: 0.9763 - val_loss: 0.1305 - val_accuracy: 0.9523 - lr: 0.0010\n",
            "Epoch 10/200\n",
            "1012/1012 [==============================] - 127s 125ms/step - loss: 0.0484 - accuracy: 0.9818 - val_loss: 0.1450 - val_accuracy: 0.9509 - lr: 0.0010\n",
            "Epoch 11/200\n",
            "1012/1012 [==============================] - 127s 125ms/step - loss: 0.0399 - accuracy: 0.9850 - val_loss: 0.1308 - val_accuracy: 0.9565 - lr: 0.0010\n",
            "Epoch 12/200\n",
            "1012/1012 [==============================] - 126s 125ms/step - loss: 0.0344 - accuracy: 0.9871 - val_loss: 0.1364 - val_accuracy: 0.9615 - lr: 0.0010\n",
            "Epoch 13/200\n",
            "1012/1012 [==============================] - 126s 125ms/step - loss: 0.0352 - accuracy: 0.9876 - val_loss: 0.1418 - val_accuracy: 0.9545 - lr: 0.0010\n",
            "Epoch 14/200\n",
            "1012/1012 [==============================] - 128s 126ms/step - loss: 0.0289 - accuracy: 0.9894 - val_loss: 0.1232 - val_accuracy: 0.9654 - lr: 0.0010\n",
            "Epoch 15/200\n",
            "1012/1012 [==============================] - 127s 125ms/step - loss: 0.0231 - accuracy: 0.9918 - val_loss: 0.1723 - val_accuracy: 0.9542 - lr: 0.0010\n",
            "Epoch 16/200\n",
            "1012/1012 [==============================] - 126s 125ms/step - loss: 0.0300 - accuracy: 0.9890 - val_loss: 0.1384 - val_accuracy: 0.9595 - lr: 0.0010\n",
            "Epoch 17/200\n",
            "1012/1012 [==============================] - 126s 125ms/step - loss: 0.0187 - accuracy: 0.9932 - val_loss: 0.1478 - val_accuracy: 0.9579 - lr: 0.0010\n",
            "Epoch 18/200\n",
            "1012/1012 [==============================] - 127s 125ms/step - loss: 0.0226 - accuracy: 0.9925 - val_loss: 0.1593 - val_accuracy: 0.9587 - lr: 0.0010\n",
            "Epoch 19/200\n",
            "1012/1012 [==============================] - 127s 125ms/step - loss: 0.0176 - accuracy: 0.9938 - val_loss: 0.1249 - val_accuracy: 0.9668 - lr: 0.0010\n",
            "Epoch 20/200\n",
            "1012/1012 [==============================] - 127s 125ms/step - loss: 0.0218 - accuracy: 0.9922 - val_loss: 0.2192 - val_accuracy: 0.9470 - lr: 0.0010\n",
            "Epoch 21/200\n",
            "1012/1012 [==============================] - 128s 126ms/step - loss: 0.0172 - accuracy: 0.9943 - val_loss: 0.1198 - val_accuracy: 0.9704 - lr: 0.0010\n",
            "Epoch 22/200\n",
            "1012/1012 [==============================] - 127s 125ms/step - loss: 0.0202 - accuracy: 0.9931 - val_loss: 0.3348 - val_accuracy: 0.9213 - lr: 0.0010\n",
            "Epoch 23/200\n",
            "1012/1012 [==============================] - 127s 125ms/step - loss: 0.0111 - accuracy: 0.9964 - val_loss: 0.1486 - val_accuracy: 0.9660 - lr: 0.0010\n",
            "Epoch 24/200\n",
            "1012/1012 [==============================] - 127s 125ms/step - loss: 0.0183 - accuracy: 0.9939 - val_loss: 0.1237 - val_accuracy: 0.9637 - lr: 0.0010\n",
            "Epoch 25/200\n",
            "1012/1012 [==============================] - 127s 125ms/step - loss: 0.0129 - accuracy: 0.9955 - val_loss: 0.1652 - val_accuracy: 0.9598 - lr: 0.0010\n",
            "Epoch 26/200\n",
            "1012/1012 [==============================] - 127s 125ms/step - loss: 0.0156 - accuracy: 0.9950 - val_loss: 0.1338 - val_accuracy: 0.9668 - lr: 0.0010\n",
            "Epoch 27/200\n",
            "1012/1012 [==============================] - 127s 125ms/step - loss: 0.0097 - accuracy: 0.9964 - val_loss: 0.1869 - val_accuracy: 0.9609 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "1012/1012 [==============================] - 126s 125ms/step - loss: 0.0171 - accuracy: 0.9943 - val_loss: 0.1570 - val_accuracy: 0.9537 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "1012/1012 [==============================] - 127s 125ms/step - loss: 0.0087 - accuracy: 0.9969 - val_loss: 0.1426 - val_accuracy: 0.9679 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "1012/1012 [==============================] - 126s 125ms/step - loss: 0.0133 - accuracy: 0.9957 - val_loss: 0.1326 - val_accuracy: 0.9718 - lr: 0.0010\n",
            "Epoch 31/200\n",
            "1012/1012 [==============================] - 126s 125ms/step - loss: 0.0100 - accuracy: 0.9964 - val_loss: 0.1589 - val_accuracy: 0.9679 - lr: 0.0010\n",
            "Starting Fold 7\n",
            "Epoch 1/200\n",
            "1012/1012 [==============================] - 127s 126ms/step - loss: 0.8654 - accuracy: 0.5469 - val_loss: 0.6308 - val_accuracy: 0.6523 - lr: 0.0010\n",
            "Epoch 2/200\n",
            "1012/1012 [==============================] - 128s 127ms/step - loss: 0.6128 - accuracy: 0.6595 - val_loss: 0.5735 - val_accuracy: 0.6900 - lr: 0.0010\n",
            "Epoch 3/200\n",
            "1012/1012 [==============================] - 128s 127ms/step - loss: 0.5323 - accuracy: 0.7282 - val_loss: 0.5279 - val_accuracy: 0.7257 - lr: 0.0010\n",
            "Epoch 4/200\n",
            "1012/1012 [==============================] - 128s 126ms/step - loss: 0.4165 - accuracy: 0.8067 - val_loss: 0.3779 - val_accuracy: 0.8267 - lr: 0.0010\n",
            "Epoch 5/200\n",
            "1012/1012 [==============================] - 129s 127ms/step - loss: 0.2785 - accuracy: 0.8824 - val_loss: 0.2777 - val_accuracy: 0.8842 - lr: 0.0010\n",
            "Epoch 6/200\n",
            "1012/1012 [==============================] - 128s 127ms/step - loss: 0.1750 - accuracy: 0.9281 - val_loss: 0.1840 - val_accuracy: 0.9233 - lr: 0.0010\n",
            "Epoch 7/200\n",
            "1012/1012 [==============================] - 128s 126ms/step - loss: 0.1058 - accuracy: 0.9595 - val_loss: 0.1638 - val_accuracy: 0.9344 - lr: 0.0010\n",
            "Epoch 8/200\n",
            "1012/1012 [==============================] - 128s 126ms/step - loss: 0.0715 - accuracy: 0.9729 - val_loss: 0.1232 - val_accuracy: 0.9545 - lr: 0.0010\n",
            "Epoch 9/200\n",
            "1012/1012 [==============================] - 127s 125ms/step - loss: 0.0589 - accuracy: 0.9787 - val_loss: 0.6682 - val_accuracy: 0.8092 - lr: 0.0010\n",
            "Epoch 10/200\n",
            "1012/1012 [==============================] - 127s 125ms/step - loss: 0.0431 - accuracy: 0.9841 - val_loss: 0.1604 - val_accuracy: 0.9459 - lr: 0.0010\n",
            "Epoch 11/200\n",
            "1012/1012 [==============================] - 126s 125ms/step - loss: 0.0406 - accuracy: 0.9851 - val_loss: 0.1913 - val_accuracy: 0.9425 - lr: 0.0010\n",
            "Epoch 12/200\n",
            "1012/1012 [==============================] - 126s 125ms/step - loss: 0.0332 - accuracy: 0.9879 - val_loss: 0.1266 - val_accuracy: 0.9621 - lr: 0.0010\n",
            "Epoch 13/200\n",
            "1012/1012 [==============================] - 126s 125ms/step - loss: 0.0340 - accuracy: 0.9880 - val_loss: 0.1448 - val_accuracy: 0.9562 - lr: 0.0010\n",
            "Epoch 14/200\n",
            "1012/1012 [==============================] - 128s 126ms/step - loss: 0.0268 - accuracy: 0.9906 - val_loss: 0.1148 - val_accuracy: 0.9660 - lr: 0.0010\n",
            "Epoch 15/200\n",
            "1012/1012 [==============================] - 127s 125ms/step - loss: 0.0246 - accuracy: 0.9912 - val_loss: 0.1396 - val_accuracy: 0.9640 - lr: 0.0010\n",
            "Epoch 16/200\n",
            "1012/1012 [==============================] - 126s 125ms/step - loss: 0.0220 - accuracy: 0.9922 - val_loss: 0.1502 - val_accuracy: 0.9587 - lr: 0.0010\n",
            "Epoch 17/200\n",
            "1012/1012 [==============================] - 126s 125ms/step - loss: 0.0210 - accuracy: 0.9924 - val_loss: 0.1282 - val_accuracy: 0.9626 - lr: 0.0010\n",
            "Epoch 18/200\n",
            "1012/1012 [==============================] - 127s 125ms/step - loss: 0.0218 - accuracy: 0.9929 - val_loss: 0.1720 - val_accuracy: 0.9506 - lr: 0.0010\n",
            "Epoch 19/200\n",
            "1012/1012 [==============================] - 127s 125ms/step - loss: 0.0180 - accuracy: 0.9937 - val_loss: 0.1314 - val_accuracy: 0.9660 - lr: 0.0010\n",
            "Epoch 20/200\n",
            "1012/1012 [==============================] - 127s 125ms/step - loss: 0.0158 - accuracy: 0.9948 - val_loss: 0.1578 - val_accuracy: 0.9601 - lr: 0.0010\n",
            "Epoch 21/200\n",
            "1012/1012 [==============================] - 127s 125ms/step - loss: 0.0176 - accuracy: 0.9939 - val_loss: 0.1744 - val_accuracy: 0.9495 - lr: 0.0010\n",
            "Epoch 22/200\n",
            "1012/1012 [==============================] - 127s 125ms/step - loss: 0.0150 - accuracy: 0.9949 - val_loss: 0.1310 - val_accuracy: 0.9643 - lr: 0.0010\n",
            "Epoch 23/200\n",
            "1012/1012 [==============================] - 127s 125ms/step - loss: 0.0182 - accuracy: 0.9936 - val_loss: 0.1297 - val_accuracy: 0.9648 - lr: 0.0010\n",
            "Epoch 24/200\n",
            "1012/1012 [==============================] - 126s 125ms/step - loss: 0.0133 - accuracy: 0.9955 - val_loss: 0.1492 - val_accuracy: 0.9587 - lr: 0.0010\n",
            "Starting Fold 8\n",
            "Epoch 1/200\n",
            "1012/1012 [==============================] - 127s 126ms/step - loss: 0.8017 - accuracy: 0.5683 - val_loss: 0.7794 - val_accuracy: 0.5176 - lr: 0.0010\n",
            "Epoch 2/200\n",
            "1012/1012 [==============================] - 128s 127ms/step - loss: 0.5894 - accuracy: 0.6837 - val_loss: 0.5162 - val_accuracy: 0.7400 - lr: 0.0010\n",
            "Epoch 3/200\n",
            " 308/1012 [========>.....................] - ETA: 1:25 - loss: 0.5186 - accuracy: 0.7446Buffered data was truncated after reaching the output size limit."
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "_y25OOebaS0N",
        "colab_type": "code",
        "outputId": "1ead5653-0729-4db4-80a4-a65dbd189a12",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        }
      },
      "source": [
        "predictions = []\n",
        "model=create_model()\n",
        "model.load_weights('modelfold1.hdf5')\n",
        "\n",
        "for i in range(1,11):\n",
        "    model.load_weights('modelfold'+str(i)+'.hdf5')\n",
        "    predictions.append(model.predict(X_validation))\n",
        "finalPredictions = np.average(predictions, axis = 0)\n",
        "finalPredictions = finalPredictions.round()\n",
        "from sklearn.metrics import accuracy_score\n",
        "accuracy_score(Y_validation, finalPredictions)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-015bdd11af20>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'modelfold1.hdf5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m11\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, filepath, by_name, skip_mismatch)\u001b[0m\n\u001b[1;32m    248\u001b[0m         raise ValueError('Load weights is not yet supported with TPUStrategy '\n\u001b[1;32m    249\u001b[0m                          'with steps_per_run greater than 1.')\n\u001b[0;32m--> 250\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mby_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_mismatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m   def compile(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/network.py\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, filepath, by_name, skip_mismatch)\u001b[0m\n\u001b[1;32m   1257\u001b[0m           'first, then load the weights.')\n\u001b[1;32m   1258\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assert_weights_created\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1259\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1260\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'layer_names'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m'model_weights'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1261\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_weights'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, **kwds)\u001b[0m\n\u001b[1;32m    406\u001b[0m                 fid = make_fid(name, mode, userblock_size,\n\u001b[1;32m    407\u001b[0m                                \u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmake_fcpl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 408\u001b[0;31m                                swmr=swmr)\n\u001b[0m\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlibver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0mflags\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r+'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: Unable to open file (unable to open file: name = 'modelfold1.hdf5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "YYCPUIphaS0R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions = []\n",
        "model=create_model()\n",
        "model.load_weights('modelfold1.hdf5')\n",
        "\n",
        "for i in range(1,11):\n",
        "    model.load_weights('modelfold'+str(i)+'.hdf5')\n",
        "    predictions.append(model.predict(X_test))\n",
        "finalPredictions = np.average(predictions, axis = 0)\n",
        "finalPredictions = finalPredictions.round()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "vJXMUJ_7aS0U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_filenames = test_fold_spectogram[1]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "m55ECpv2aS0X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(mcp_save_drive+\"submisieCross.txt\", \"w+\") as f:\n",
        "    f.write(\"name,label\\n\")\n",
        "    for i in range(0, len(test_filenames)):\n",
        "        f.write(test_filenames[i] + \".wav,\" + str(int(finalPredictions[i][0]))+\"\\n\")\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5KHsCw9BNv3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6oWt1NevRLQ6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}