{"cells":[{"metadata":{},"cell_type":"markdown","source":"Interesting paper https://reader.elsevier.com/reader/sd/pii/S1877050917316599?token=63147E6FB36A421DB648052F0A734C07182BF929F1E6FE4F62F2F0CA6A280FAE311F85835C9CC3F188C17B1458D1A80D"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport IPython.display as ipd # to display audio inside jupyter\n#import librosa # Audio parsing\n#import librosa.display\nimport matplotlib.pyplot as plt # to make graphs\nimport sklearn # Ml\nfrom tqdm import tqdm_notebook as tqdm # progress bar\nimport multiprocessing # going faster\nfrom multiprocessing import Pool\nimport time\nimport glob\nimport gc\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.preprocessing.image import load_img\nfrom tensorflow.keras.preprocessing.image import img_to_array\nfrom tensorflow.keras.preprocessing.image import array_to_img\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('/kaggle/input/surgical-mask-create-images/train/fold_spectogram/images'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":1,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"images_input =  \"surgical-mask-create-images\"","execution_count":2,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# reading competition data\ndef f_path(fileName, tpe = None):\n    \"\"\"\n    Adds full path to a filename recived\n    tpe = None / validation / train / test\n    \"\"\"\n    if tpe == None:\n        return \"/kaggle/input/ml-fmi-23-2020/\" + fileName\n    else:\n        return \"/kaggle/input/ml-fmi-23-2020/\" + tpe + \"/\" + tpe + \"/\" + fileName\n    \ndef split_into_files(file):\n    \"\"\"\n    Splits the recived input into files\n    \"\"\"\n    file = file.split(\"\\n\")\n    file = [x.split(\",\") for x in file]\n    return file\n# Reading the file names\nwith open(f_path(\"train.txt\"), \"r\") as f:\n    trainFileNames = split_into_files(f.read())\nwith open(f_path(\"validation.txt\"), \"r\") as f:\n    validationFileNames = split_into_files(f.read())\nwith open(f_path(\"test.txt\"), \"r\") as f:\n    testFileNames = split_into_files(f.read())","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Reading competition data\ntrainFileNames = trainFileNames[:-1]\ntrainOnlyFilesNames = [x[0] for x in trainFileNames]\ntrainLabels = [int(x[1]) for x in trainFileNames]\n\nvalidationFileNames = validationFileNames[:-1]\nvalidationOnlyFilesNames = [x[0] for x in validationFileNames]\nvalidationLabels = [int(x[1]) for x in validationFileNames]\n\ntestFileNames = testFileNames[:-1]\ntestOnlyFilesNames = [x[0] for x in validationFileNames]\n","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def read_images_from_dir(directory):\n    files = glob.glob(directory + \"/*\")\n    #images = [load_img(x) for x in files]\n    images = [load_img(x, grayscale=True) for x in files]\n    filesId = [x.split('/')[-1].split('.')[0] for x in files]\n    \n    return images, filesId\n\ndef read_all_images_for(dataType, spectogramType):\n    \"\"\"\n    spectogramTypes = fold_spectogram / mfcc_spectogram / crf_spectogram\n    \n    \"\"\"\n    spectogramDir = \"/kaggle/input/\"+images_input+\"/\"+dataType+\"/\"+spectogramType+\"/images\"\n    spectogram = read_images_from_dir(spectogramDir) \n    return spectogram\n    \n# Reading image data\n\ntrainDir = \"/kaggle/input/\"+images_input+\"/train\"\nvalidationDir = \"/kaggle/input/\"+images_input+\"/validation\"\ntestDir = \"/kaggle/input/\"+images_input+\"/test\"\n\ntest_fold_spectogram = read_all_images_for(\"test\", \"fold_spectogram\")\n# test_mfcc_spectogram = read_all_images_for(\"test\", \"mfcc_spectogram\")\n# test_crf_spectogram = read_all_images_for(\"test\", \"crf_spectogram\")\n\ntrain_fold_spectogram = read_all_images_for(\"train\", \"fold_spectogram\")\n# train_mfcc_spectogram = read_all_images_for(\"train\", \"mfcc_spectogram\")\n# train_crf_spectogram = read_all_images_for(\"train\", \"crf_spectogram\")\n\nvalidation_fold_spectogram = read_all_images_for(\"validation\", \"fold_spectogram\")\n# validation_mfcc_spectogram = read_all_images_for(\"validation\", \"mfcc_spectogram\")\n# validation_crf_spectogram = read_all_images_for(\"validation\", \"crf_spectogram\")","execution_count":5,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.7/site-packages/keras_preprocessing/image/utils.py:104: UserWarning: grayscale is deprecated. Please use color_mode = \"grayscale\"\n  warnings.warn('grayscale is deprecated. Please use '\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # Combining images\n# validation_spectogram = [[],[]]\n\n# for i in range(len(validation_fold_spectogram[0])):\n#     validation_spectogram[0].append((validation_fold_spectogram[0][i], validation_mfcc_spectogram[0][i], validation_crf_spectogram[0][i]))\n# validation_spectogram[1] = validation_fold_spectogram[1]\n\n# train_spectogram = [[],[]]\n\n# for i in range(len(train_fold_spectogram[0])):\n#     train_spectogram[0].append((train_fold_spectogram[0][i], train_mfcc_spectogram[0][i], train_crf_spectogram[0][i]))\n#     train_spectogram[1] = train_fold_spectogram[1]\n\n# test_spectogram = [[],[]]\n\n# for i in range(len(test_fold_spectogram[0])):\n#     test_spectogram[0].append((test_fold_spectogram[0][i], test_mfcc_spectogram[0][i], test_crf_spectogram[0][i]))\n#     test_spectogram[1] = test_fold_spectogram[1]","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# def augment_data_horizontal(spectogram):\n#     images= spectogram[0]\n#     names = spectogram[1]\n#     augmented_data = []\n#     augmented_names = []\n#     for i in range(len(images)):\n#         image = images[i]\n#         name = names[i]\n#         image_ar = img_to_array(image)\n#         image_ar = np.flip(image_ar, axis = 1)\n#         augmented_image = array_to_img(image_ar)\n        \n#         augmented_data.append(image)\n#         augmented_data.append(augmented_image)\n#         augmented_names.append(name)\n#         augmented_names.append(name)\n\n#     return augmented_data, augmented_names\n\n# def augment_data_vertical(spectogram):\n#     images= spectogram[0]\n#     names = spectogram[1]\n#     augmented_data = []\n#     augmented_names = []\n#     for i in range(len(images)):\n#         image = images[i]\n#         name = names[i]\n#         image_ar = img_to_array(image)\n#         image_ar = np.flip(image_ar, axis = 0)\n#         augmented_image = array_to_img(image_ar)\n        \n#         augmented_data.append(image)\n#         augmented_data.append(augmented_image)\n#         augmented_names.append(name)\n#         augmented_names.append(name)\n#     return augmented_data, augmented_names ","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#augmented_train_fold_spectogram = augment_data_horizontal(train_fold_spectogram)\n#augmented_train_fold_spectogram = augment_data_vertical(augmented_train_fold_spectogram)","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class DataGenerator(keras.utils.Sequence):\n    def __image_processing(self, image):\n        image_ar = img_to_array(image)\n        return image_ar\n        #return np.concatenate((img_to_array(image[0]), img_to_array(image[1]), img_to_array(image[2])), axis = 2) # for 3 images in one\n    def __get_label_from_aid(self,aid):\n        try:\n            index = trainOnlyFilesNames.index(str(aid) + \".wav\")\n            return trainLabels[index]\n        except:\n            pass\n        try:\n            index = validationOnlyFilesNames.index(str(aid) + \".wav\")\n            return validationLabels[index]\n        except:\n            pass\n        return -1\n    def __split_image_list_into_labels(self, list_images):\n        images = []\n        for i in range(len(list_images[0])):\n            images.append(\n                (list_images[0][i], list_images[1][i]))   \n        return images\n    \n    def __init__(self, list_images, batch_size=32, dim=(32, 32, 32), n_channels=1,\n                 n_classes=2, shuffle=True, augment=False):\n        'Initialization'\n        self.dim = dim\n        self.batch_size = batch_size\n        self.list_images = self.__split_image_list_into_labels(list_images)\n        self.n_channels = n_channels\n        self.n_classes = n_classes\n        self.shuffle = shuffle\n        self.augment = augment\n        self.on_epoch_end()\n\n    def on_epoch_end(self):\n        'Updates indexes after each epoch'\n        self.indexes = np.arange(len(self.list_images))\n        if self.shuffle == True:\n            np.random.shuffle(self.indexes)\n\n    def __data_generation(self, list_images_temp):\n        # X : (n_samples, *dim, n_channels)\n        'Generates data containing batch_size samples'\n        # Initialization\n        #X = np.empty((self.batch_size, *self.dim, self.n_channels))\n        #y = np.empty((self.batch_size), dtype=int)\n        X = [0] * self.batch_size\n        y = [0] * self.batch_size\n        # Generate data\n        for i, images in enumerate(list_images_temp):\n            # Store sample\n            X[i] = self.__image_processing(images[0])\n            # Store class\n            y[i] = self.__get_label_from_aid(images[1])\n        \n        X = np.asarray(X)\n        y = np.asarray(y)\n        return X, y\n\n    def __len__(self):\n        'Denotes the number of batches per epoch'\n        return int(np.floor(len(self.list_images) / self.batch_size))\n\n    def __getitem__(self, index):\n        'Generate one batch of data'\n        # Generate indexes of the batch\n        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n\n        # Find list of images\n        list_images_temp = [self.list_images[k] for k in indexes]\n\n        # Generate data\n        X, y = self.__data_generation(list_images_temp)\n\n        return X, y\n","execution_count":9,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_label_from_aid(aid):\n    try:\n        index = trainOnlyFilesNames.index(str(aid) + \".wav\")\n        return trainLabels[index]\n    except:\n        pass\n    try:\n        index = validationOnlyFilesNames.index(str(aid) + \".wav\")\n        return validationLabels[index]\n    except:\n        pass\n    return -1\n\ndef preproces_images(images):\n    newImages = [img_to_array(x) for x in images]\n    return newImages\n\ndef generate_data_and_labels(data):\n    images, fileNames = data\n    \n    X = preproces_images(images)\n    Y = [get_label_from_aid(x) for x in fileNames]\n    \n    return X, Y\n\ndef generate_labels(data):\n    images, fileNames = data\n    \n    Y = [get_label_from_aid(x) for x in fileNames]\n    \n    return Y","execution_count":10,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# X_train, Y_train = generate_data_and_labels(train_fold_spectogram)\n# X_validation, Y_validation = generate_data_and_labels(validation_fold_spectogram)\n\n# X_train = np.asarray(X_train)\n# X_validation = np.asarray(X_validation)\n\n# Y_train = np.asarray(Y_train)\n# Y_validation = np.asarray(Y_validation)\n# X_test = np.array(generate_data_and_labels(test_fold_spectogram)[0])\n\n# del train_fold_spectogram\n# del validation_fold_spectogram\n# gc.collect()","execution_count":11,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_validation, Y_validation = generate_data_and_labels(validation_fold_spectogram)\nX_test = np.array(generate_data_and_labels(test_fold_spectogram)[0])\nX_validation = np.asarray(X_validation)","execution_count":12,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y_train = generate_labels(train_fold_spectogram)\nY_train = np.asarray(Y_train)","execution_count":13,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_generator = DataGenerator(train_fold_spectogram)\nvalidation_generator = DataGenerator(validation_fold_spectogram)","execution_count":14,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras import Sequential\nfrom tensorflow.keras.layers import Dense, InputLayer, LSTM, Bidirectional, GlobalMaxPooling1D, Conv2D, Dropout, MaxPooling2D,Input,ThresholdedReLU, Flatten, BatchNormalization, Activation, GlobalMaxPooling2D, concatenate, GlobalAveragePooling2D, AveragePooling2D\nfrom keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, CSVLogger, Callback, EarlyStopping\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, CSVLogger, Callback, EarlyStopping\nimport sklearn\nfrom tensorflow.keras.applications.resnet50 import ResNet50\n\n","execution_count":30,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# main_input = Input(shape = (217, 223, 1))\n# x = Conv2D(64, (3, 3), kernel_initializer='he_uniform', padding='same')(main_input)\n# x = BatchNormalization()(x)\n# x = MaxPooling2D((3,3))(x)\n# skip1 = x\n# x = Activation(\"relu\")(x)\n\n# x = Conv2D(64, (3, 3), kernel_initializer='he_uniform', padding='same')(x)\n# x = BatchNormalization()(x)\n# x = Activation(\"relu\")(x)\n# x = Conv2D(64, (3, 3), kernel_initializer='he_uniform', padding='same')(x)\n# x = BatchNormalization()(x)\n# skip2 = concatenate([skip1, x])\n# x = skip2\n# x = Activation(\"relu\")(x)\n\n# x = Conv2D(64, (3, 3), kernel_initializer='he_uniform', padding='same')(x)\n# x = BatchNormalization()(x)\n# x = Activation(\"relu\")(x)\n# x = Conv2D(64, (3, 3), kernel_initializer='he_uniform', padding='same')(x)\n# x = BatchNormalization()(x)\n# skip3 = concatenate([skip2, x])\n# x = skip3\n# x = Activation(\"relu\")(x)\n\n# x = Conv2D(64, (3, 3), kernel_initializer='he_uniform', padding='same')(x)\n# x = BatchNormalization()(x)\n# x = Activation(\"relu\")(x)\n# x = Conv2D(64, (3, 3), kernel_initializer='he_uniform', padding='same')(x)\n# x = BatchNormalization()(x)\n# skip4 = concatenate([skip3, x])\n# x = skip4\n# x = Activation(\"relu\")(x)\n\n# x = Conv2D(64, (3, 3), kernel_initializer='he_uniform', padding='same')(x)\n# x = BatchNormalization()(x)\n# x = Activation(\"relu\")(x)\n# x = Conv2D(64, (3, 3), kernel_initializer='he_uniform', padding='same')(x)\n# x = BatchNormalization()(x)\n# skip5 = concatenate([skip4, x])\n# x = skip5\n# x = Activation(\"relu\")(x)\n# x = MaxPooling2D((2,2))(x)\n# x = Flatten()(x)\n\n\n# x = Dense(128, activation='relu', kernel_initializer='he_uniform')(x)\n# x = Dense(64, activation='relu', kernel_initializer='he_uniform')(x)\n# output = Dense(1, activation='sigmoid')(x)\n\n# model = Model(inputs=main_input, outputs=output)\n# model.compile(optimizer=\"adam\", loss='binary_crossentropy', metrics=['accuracy'])","execution_count":31,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"main_input = Input(shape = (217, 223, 1))\nx = Conv2D(32, (3, 3), kernel_initializer='he_uniform', padding='same')(main_input)\nx = BatchNormalization()(x)\nx = Activation(\"relu\")(x)\nx = Conv2D(32, (3, 3), kernel_initializer='he_uniform', padding='same')(x)\nx = BatchNormalization()(x)\nx = Activation(\"relu\")(x)\nx = Conv2D(32, (3, 3), kernel_initializer='he_uniform', padding='same')(x)\nx = BatchNormalization()(x)\nx = Activation(\"relu\")(x)\nx = MaxPooling2D((3,3))(x)\n\nx = Conv2D(64, (3, 3), kernel_initializer='he_uniform', padding='same')(x)\nx = BatchNormalization()(x)\nx = Activation(\"relu\")(x)\nx = Conv2D(64, (3, 3), kernel_initializer='he_uniform', padding='same')(x)\nx = BatchNormalization()(x)\nx = Activation(\"relu\")(x)\nx = Conv2D(64, (3, 3), kernel_initializer='he_uniform', padding='same')(x)\nx = BatchNormalization()(x)\nx = Activation(\"relu\")(x)\nx = MaxPooling2D((3,3))(x)\n\nx = Conv2D(128, (3, 3), kernel_initializer='he_uniform', padding='same')(x)\nx = BatchNormalization()(x)\nx = Activation(\"relu\")(x)\nx = Conv2D(128, (3, 3), kernel_initializer='he_uniform', padding='same')(x)\nx = BatchNormalization()(x)\nx = Activation(\"relu\")(x)\nx = Conv2D(128, (3, 3), kernel_initializer='he_uniform', padding='same')(x)\nx = BatchNormalization()(x)\nx = Activation(\"relu\")(x)\nx = MaxPooling2D((3,3))(x)\nx = Flatten()(x)\n\nx = Dense(128, activation='relu', kernel_initializer='he_uniform')(x)\nx = Dense(64, activation='relu', kernel_initializer='he_uniform')(x)\noutput = Dense(1, activation='sigmoid')(x)\n\nmodel = Model(inputs=main_input, outputs=output)\nmodel.compile(optimizer=\"adam\", loss='binary_crossentropy', metrics=['accuracy'])","execution_count":32,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#model.fit(X_train, Y_train, epochs = 50, validation_data= (X_validation, Y_validation),  batch_size = 32)\nclass_weight = sklearn.utils.class_weight.compute_class_weight('balanced',np.unique(Y_train), Y_train)\nmcp_save = ModelCheckpoint('model.hdf5', save_best_only=True, monitor='val_loss', mode='min')\n\nmodel.fit(x = train_generator, epochs = 200, validation_data=validation_generator, shuffle=True,\n                         class_weight = class_weight, \n                callbacks= [\n                              EarlyStopping(patience=10, monitor='val_loss', mode='min'),\n                              mcp_save,\n                              ReduceLROnPlateau(factor=.3)\n                         ])","execution_count":42,"outputs":[{"output_type":"stream","text":"Train for 250 steps, validate for 31 steps\nEpoch 1/200\n250/250 [==============================] - 9s 37ms/step - loss: 1.4003 - accuracy: 0.5469 - val_loss: 0.7967 - val_accuracy: 0.5917\nEpoch 2/200\n250/250 [==============================] - 8s 33ms/step - loss: 0.8276 - accuracy: 0.6059 - val_loss: 0.6396 - val_accuracy: 0.6411\nEpoch 3/200\n250/250 [==============================] - 8s 32ms/step - loss: 0.6538 - accuracy: 0.6484 - val_loss: 0.8837 - val_accuracy: 0.5393\nEpoch 4/200\n250/250 [==============================] - 8s 33ms/step - loss: 0.6187 - accuracy: 0.6747 - val_loss: 0.6137 - val_accuracy: 0.6683\nEpoch 5/200\n250/250 [==============================] - 8s 33ms/step - loss: 0.5553 - accuracy: 0.7210 - val_loss: 0.6109 - val_accuracy: 0.6734\nEpoch 6/200\n250/250 [==============================] - 8s 34ms/step - loss: 0.5184 - accuracy: 0.7383 - val_loss: 0.6768 - val_accuracy: 0.6502\nEpoch 7/200\n250/250 [==============================] - 8s 33ms/step - loss: 0.4801 - accuracy: 0.7663 - val_loss: 0.6292 - val_accuracy: 0.6845\nEpoch 8/200\n250/250 [==============================] - 8s 33ms/step - loss: 0.4603 - accuracy: 0.7782 - val_loss: 0.6324 - val_accuracy: 0.6764\nEpoch 9/200\n250/250 [==============================] - 8s 33ms/step - loss: 0.4025 - accuracy: 0.8211 - val_loss: 0.5883 - val_accuracy: 0.7177\nEpoch 10/200\n250/250 [==============================] - 8s 32ms/step - loss: 0.3810 - accuracy: 0.8251 - val_loss: 0.6692 - val_accuracy: 0.6885\nEpoch 11/200\n250/250 [==============================] - 8s 32ms/step - loss: 0.3388 - accuracy: 0.8497 - val_loss: 0.7571 - val_accuracy: 0.6522\nEpoch 12/200\n250/250 [==============================] - 8s 32ms/step - loss: 0.2889 - accuracy: 0.8798 - val_loss: 0.8020 - val_accuracy: 0.6502\nEpoch 13/200\n250/250 [==============================] - 8s 32ms/step - loss: 0.2307 - accuracy: 0.9072 - val_loss: 0.7511 - val_accuracy: 0.7026\nEpoch 14/200\n250/250 [==============================] - 8s 34ms/step - loss: 0.1916 - accuracy: 0.9237 - val_loss: 0.7013 - val_accuracy: 0.7137\nEpoch 15/200\n250/250 [==============================] - 8s 32ms/step - loss: 0.1544 - accuracy: 0.9402 - val_loss: 0.8143 - val_accuracy: 0.6956\nEpoch 16/200\n250/250 [==============================] - 8s 32ms/step - loss: 0.1569 - accuracy: 0.9396 - val_loss: 1.1065 - val_accuracy: 0.6804\nEpoch 17/200\n250/250 [==============================] - 8s 32ms/step - loss: 0.1070 - accuracy: 0.9626 - val_loss: 0.9544 - val_accuracy: 0.6895\nEpoch 18/200\n250/250 [==============================] - 8s 32ms/step - loss: 0.1004 - accuracy: 0.9610 - val_loss: 0.8432 - val_accuracy: 0.7188\nEpoch 19/200\n250/250 [==============================] - 8s 32ms/step - loss: 0.0573 - accuracy: 0.9819 - val_loss: 1.0412 - val_accuracy: 0.6996\n","name":"stdout"},{"output_type":"execute_result","execution_count":42,"data":{"text/plain":"<tensorflow.python.keras.callbacks.History at 0x7f1c9ec72290>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.load_weights('model.hdf5')\npredictions = model.predict(X_test).round()\nfinalPredictions = predictions","execution_count":43,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"validation_predictions = model.predict(X_validation).round()\nfrom sklearn.metrics import accuracy_score\naccuracy_score(Y_validation, validation_predictions)","execution_count":44,"outputs":[{"output_type":"execute_result","execution_count":44,"data":{"text/plain":"0.716"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# full_data = np.concatenate((train_fold_spectogram, validation_fold_spectogram))\n# Y_full = np.concatenate((Y_train, Y_validation))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# def create_model():\n#     main_input = Input(shape = (217, 223, 3))\n#     x = Conv2D(32, (3, 3), kernel_initializer='he_uniform', padding='same')(main_input)\n#     x = BatchNormalization()(x)\n#     x = Activation(\"relu\")(x)\n#     x = Conv2D(32, (3, 3), kernel_initializer='he_uniform', padding='same')(main_input)\n#     x = BatchNormalization()(x)\n#     x = Activation(\"relu\")(x)\n#     x = Conv2D(32, (3, 3), kernel_initializer='he_uniform', padding='same')(main_input)\n#     x = BatchNormalization()(x)\n#     x = Activation(\"relu\")(x)\n#     x = MaxPooling2D((2,2))(x)\n\n#     x = Conv2D(64, (3, 3), kernel_initializer='he_uniform', padding='same')(main_input)\n#     x = BatchNormalization()(x)\n#     x = Activation(\"relu\")(x)\n#     x = Conv2D(64, (3, 3), kernel_initializer='he_uniform', padding='same')(main_input)\n#     x = BatchNormalization()(x)\n#     x = Activation(\"relu\")(x)\n#     x = Conv2D(64, (3, 3), kernel_initializer='he_uniform', padding='same')(main_input)\n#     x = BatchNormalization()(x)\n#     x = Activation(\"relu\")(x)\n#     x = MaxPooling2D((2,2))(x)\n\n#     x = Conv2D(128, (3, 3), kernel_initializer='he_uniform', padding='same')(main_input)\n#     x = BatchNormalization()(x)\n#     x = Activation(\"relu\")(x)\n#     x = Conv2D(128, (3, 3), kernel_initializer='he_uniform', padding='same')(main_input)\n#     x = BatchNormalization()(x)\n#     x = Activation(\"relu\")(x)\n#     x = Conv2D(128, (3, 3), kernel_initializer='he_uniform', padding='same')(main_input)\n#     x = BatchNormalization()(x)\n#     x = Activation(\"relu\")(x)\n#     x = MaxPooling2D((2,2))(x)\n#     x = Flatten()(x)\n\n#     x = Dense(128, activation='relu', kernel_initializer='he_uniform')(x)\n#     x = Dense(64, activation='relu', kernel_initializer='he_uniform')(x)\n#     output = Dense(1, activation='sigmoid')(x)\n\n#     model = Model(inputs=main_input, outputs=output)\n#     model.compile(optimizer=\"adam\", loss='binary_crossentropy', metrics=['accuracy'])\n#     return model\n\n# from sklearn.model_selection import KFold\n\n\n\n# curentFold = 0\n# kf = KFold(n_splits=10, shuffle = True, random_state = 42)\n# for train_index, test_index in kf.split(X_full):\n    \n#     curentFold += 1\n#     gc.collect()\n#     X_train_fold = np.array([X_full[x] for x in train_index])\n#     X_test_fold = np.array([X_full[x] for x in test_index])\n    \n#     Y_train_fold = np.array([Y_full[x] for x in train_index])\n#     Y_test_fold = np.array([Y_full[x] for x in test_index])\n    \n#     train_generator = DataGenerator(train_fold_spectogram)\n#     validation_generator = DataGenerator(validation_fold_spectogram)\n    \n#     class_weight = sklearn.utils.class_weight.compute_class_weight('balanced',np.unique(Y_train_fold), Y_train_fold)\n    \n#     model=create_model()\n#     mcp_save = ModelCheckpoint('modelfold'+str(curentFold)+'.hdf5', save_best_only=True, monitor='val_loss', mode='min')\n#     model.fit(x = train_generator, epochs = 200, validation_data=validation_generator, shuffle=True,\n#                          class_weight = class_weight, \n#                 callbacks= [\n#                               EarlyStopping(patience=10, monitor='val_loss', mode='min'),\n#                               mcp_save,\n#                               ReduceLROnPlateau(factor=.3)\n#                          ])\n    \n    \n#     print(\"Fold \"+str(curentFold)+\" done.\")\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# validation_fold_spectogram = read_all_images_for(\"validation\", \"fold_spectogram\")\n# X_validation, Y_validation = generate_data_and_labels(validation_fold_spectogram)\n# X_validation = np.array(X_validation)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # 6  didn't learn anything\n# predictions = []\n# model=create_model()\n# model.load_weights('modelfold1.hdf5')\n\n# for i in range(1,11):\n#     if i == 8 or i == 4:\n#         continue\n#     model.load_weights('modelfold'+str(i)+'.hdf5')\n#     predictions.append(model.predict(X_validation))\n# finalPredictions = np.average(predictions, axis = 0)\n# finalPredictions = finalPredictions.round()\n# from sklearn.metrics import accuracy_score\n# accuracy_score(Y_validation, finalPredictions)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# predictions = []\n# model=create_model()\n# model.load_weights('modelfold1.hdf5')\n\n# for i in range(1,11):\n#     if i == 8 or i == 4:\n#         continue\n#     model.load_weights('modelfold'+str(i)+'.hdf5')\n#     predictions.append(model.predict(X_test))\n# finalPredictions = np.average(predictions, axis = 0)\n# finalPredictions = finalPredictions.round()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_filenames = test_fold_spectogram[1]\n","execution_count":45,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with open(\"submisie5.txt\", \"w+\") as f:\n    f.write(\"name,label\\n\")\n    for i in range(0, len(test_filenames)):\n        f.write(test_filenames[i] + \".wav,\" + str(int(finalPredictions[i][0]))+\"\\n\")","execution_count":46,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}