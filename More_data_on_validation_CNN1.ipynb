{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "More data on validation CNN1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WxX_LQ0naSy0",
        "colab_type": "text"
      },
      "source": [
        "Interesting paper https://reader.elsevier.com/reader/sd/pii/S1877050917316599?token=63147E6FB36A421DB648052F0A734C07182BF929F1E6FE4F62F2F0CA6A280FAE311F85835C9CC3F188C17B1458D1A80D"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ed3wu1b_abi1",
        "colab_type": "code",
        "outputId": "240a780d-b5e5-4cbc-83e7-909f1fa13b6d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "# getting the data\n",
        "!git clone https://mihainsto:0dabea4eb5ec4a2ec6feff5cdbb6a9837fa0c342@github.com/mihainsto/Surgical-Mask-Audio-ML.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Surgical-Mask-Audio-ML'...\n",
            "remote: Enumerating objects: 3, done.\u001b[K\n",
            "remote: Counting objects:  33% (1/3)\u001b[K\rremote: Counting objects:  66% (2/3)\u001b[K\rremote: Counting objects: 100% (3/3)\u001b[K\rremote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 95739 (delta 0), reused 2 (delta 0), pack-reused 95736\u001b[K\n",
            "Receiving objects: 100% (95739/95739), 1.83 GiB | 38.25 MiB/s, done.\n",
            "Resolving deltas: 100% (49/49), done.\n",
            "Checking out files: 100% (92012/92012), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "nxfm4F__aSy2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "import IPython.display as ipd # to display audio inside jupyter\n",
        "#import librosa # Audio parsing\n",
        "#import librosa.display\n",
        "import matplotlib.pyplot as plt # to make graphs\n",
        "import sklearn # Ml\n",
        "from tqdm import tqdm_notebook as tqdm # progress bar\n",
        "import multiprocessing # going faster\n",
        "from multiprocessing import Pool\n",
        "import time\n",
        "import glob\n",
        "import gc\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras.preprocessing.image import array_to_img\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "# for dirname, _, filenames in os.walk('/kaggle/input/surgical-mask-create-images/train/fold_spectogram/images'):\n",
        "#     for filename in filenames:\n",
        "#         print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R9FwUoRfmE0w",
        "colab_type": "code",
        "outputId": "7ee1e801-6938-496e-87ab-6ef3f029fc85",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "!rm -rf \"Surgical-Mask-Audio-ML/kfold\"\n",
        "!ls \"Surgical-Mask-Audio-ML\""
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'augment shift and speed validation.py'\n",
            "'Cross validation augmented speed skip CNN1.ipynb'\n",
            "'Image Recognition Surgical Mask Audio.ipynb'\n",
            " ml-fmi-23-2020\n",
            " README.md\n",
            "'Surgical Mask images aug time shift and speed .ipynb'\n",
            "'Surgical Mask images aug time shift and speed .py'\n",
            " test\n",
            " train\n",
            " validation\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "GWtY6pJwaSy7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "images_input =  \"surgical-mask-create-images\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "trusted": true,
        "id": "u3M9fxfdaSzA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# reading competition data\n",
        "def f_path(fileName, tpe = None):\n",
        "    \"\"\"\n",
        "    Adds full path to a filename recived\n",
        "    tpe = None / validation / train / test\n",
        "    \"\"\"\n",
        "    if tpe == None:\n",
        "        return \"Surgical-Mask-Audio-ML/ml-fmi-23-2020/\" + fileName\n",
        "    else:\n",
        "        return \"Surgical-Mask-Audio-ML/ml-fmi-23-2020/\" + tpe + \"/\" + tpe + \"/\" + fileName\n",
        "    \n",
        "def split_into_files(file):\n",
        "    \"\"\"\n",
        "    Splits the recived input into files\n",
        "    \"\"\"\n",
        "    file = file.split(\"\\n\")\n",
        "    file = [x.split(\",\") for x in file]\n",
        "    return file\n",
        "# Reading the file names\n",
        "with open(f_path(\"train.txt\"), \"r\") as f:\n",
        "    trainFileNames = split_into_files(f.read())\n",
        "with open(f_path(\"validation.txt\"), \"r\") as f:\n",
        "    validationFileNames = split_into_files(f.read())\n",
        "with open(f_path(\"test.txt\"), \"r\") as f:\n",
        "    testFileNames = split_into_files(f.read())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "ljK0rBwqaSzD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Reading competition data\n",
        "trainFileNames = trainFileNames[:-1]\n",
        "trainOnlyFilesNames = [x[0] for x in trainFileNames]\n",
        "trainLabels = [int(x[1]) for x in trainFileNames]\n",
        "\n",
        "validationFileNames = validationFileNames[:-1]\n",
        "validationOnlyFilesNames = [x[0] for x in validationFileNames]\n",
        "validationLabels = [int(x[1]) for x in validationFileNames]\n",
        "\n",
        "testFileNames = testFileNames[:-1]\n",
        "testOnlyFilesNames = [x[0] for x in validationFileNames]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Wk-67Rb8aSzG",
        "colab_type": "code",
        "outputId": "50fc7111-35dc-4e1f-fed9-0129a490f526",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "def read_images_from_dir(directory):\n",
        "    files = glob.glob(directory + \"/*\")\n",
        "    print(directory)\n",
        "    #images = [load_img(x) for x in files]\n",
        "    images = [load_img(x, grayscale=True) for x in files]\n",
        "    filesId = [x.split('/')[-1].split('.')[0] for x in files]\n",
        "    \n",
        "    return images, filesId\n",
        "\n",
        "def read_all_images_for(dataType, spectogramType):\n",
        "    \"\"\"\n",
        "    spectogramTypes = fold_spectogram / mfcc_spectogram / crf_spectogram\n",
        "    \n",
        "    \"\"\"\n",
        "    spectogramDir = \"Surgical-Mask-Audio-ML/\"+dataType+\"/\"+spectogramType+\"/images\"\n",
        "\n",
        "      \n",
        "    spectogram = read_images_from_dir(spectogramDir) \n",
        "    return spectogram\n",
        "    \n",
        "# Reading image data\n",
        "\n",
        "\n",
        "\n",
        "test_fold_spectogram = read_all_images_for(\"test\", \"fold_spectogram\")\n",
        "# test_mfcc_spectogram = read_all_images_for(\"test\", \"mfcc_spectogram\")\n",
        "# test_crf_spectogram = read_all_images_for(\"test\", \"crf_spectogram\")\n",
        "\n",
        "train_fold_spectogram = read_all_images_for(\"train\", \"fold_spectogram\")\n",
        "# train_mfcc_spectogram = read_all_images_for(\"train\", \"mfcc_spectogram\")\n",
        "# train_crf_spectogram = read_all_images_for(\"train\", \"crf_spectogram\")\n",
        "\n",
        "validation_fold_spectogram = read_all_images_for(\"validation\", \"fold_spectogram\")\n",
        "# validation_mfcc_spectogram = read_all_images_for(\"validation\", \"mfcc_spectogram\")\n",
        "# validation_crf_spectogram = read_all_images_for(\"validation\", \"crf_spectogram\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Surgical-Mask-Audio-ML/test/fold_spectogram/images\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/utils.py:104: UserWarning: grayscale is deprecated. Please use color_mode = \"grayscale\"\n",
            "  warnings.warn('grayscale is deprecated. Please use '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Surgical-Mask-Audio-ML/train/fold_spectogram/images\n",
            "Surgical-Mask-Audio-ML/validation/fold_spectogram/images\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "hsFwd325aSzW",
        "colab_type": "code",
        "outputId": "ae1f3989-31b3-4bac-d6e3-c73077d501b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# removing augmented data\n",
        "new_train_fold_spectogram = ([],[])\n",
        "train_fold_spectogram\n",
        "for i in range(len(train_fold_spectogram[1])):\n",
        "  if 'a' not in train_fold_spectogram[1][i]:\n",
        "    new_train_fold_spectogram[0].append(train_fold_spectogram[0][i])\n",
        "    new_train_fold_spectogram[1].append(train_fold_spectogram[1][i])\n",
        "\n",
        "train_fold_spectogram = new_train_fold_spectogram\n",
        "len(train_fold_spectogram[1])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "feyXsQAYqx54",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "d7939335-d001-4a2a-ad20-991727f5e958"
      },
      "source": [
        "#Moving 1k data from train to validation\n",
        "len(train_fold_spectogram[1])\n",
        "for i in range(0,1000):\n",
        "  validation_fold_spectogram[0].append(train_fold_spectogram[0][i])\n",
        "  validation_fold_spectogram[1].append(train_fold_spectogram[1][i])\n",
        "\n",
        "  del train_fold_spectogram[0][i]\n",
        "  del train_fold_spectogram[1][i]\n",
        "\n",
        "print(len(train_fold_spectogram[0]))\n",
        "print(len(validation_fold_spectogram[0]))\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7000\n",
            "2000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Gg8md2skaSzc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DataGenerator(keras.utils.Sequence):\n",
        "    def __image_processing(self, image):\n",
        "        image_ar = img_to_array(image)\n",
        "        return image_ar\n",
        "        #return np.concatenate((img_to_array(image[0]), img_to_array(image[1]), img_to_array(image[2])), axis = 2) # for 3 images in one\n",
        "    def __get_label_from_aid(self,aid):\n",
        "        aid = aid.replace('a', '')\n",
        "        try:\n",
        "            index = trainOnlyFilesNames.index(str(aid) + \".wav\")\n",
        "            return trainLabels[index]\n",
        "        except:\n",
        "            pass\n",
        "        try:\n",
        "            index = validationOnlyFilesNames.index(str(aid) + \".wav\")\n",
        "            return validationLabels[index]\n",
        "        except:\n",
        "            pass\n",
        "        return -1\n",
        "    def __split_image_list_into_labels(self, list_images):\n",
        "        images = []\n",
        "        for i in range(len(list_images[0])):\n",
        "            images.append(\n",
        "                (list_images[0][i], list_images[1][i]))   \n",
        "        return images\n",
        "    \n",
        "    def __init__(self, list_images, batch_size=32, dim=(32, 32, 32), n_channels=1,\n",
        "                 n_classes=2, shuffle=True, augment=False):\n",
        "        'Initialization'\n",
        "        self.dim = dim\n",
        "        self.batch_size = batch_size\n",
        "        self.list_images = self.__split_image_list_into_labels(list_images)\n",
        "        self.n_channels = n_channels\n",
        "        self.n_classes = n_classes\n",
        "        self.shuffle = shuffle\n",
        "        self.augment = augment\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        'Updates indexes after each epoch'\n",
        "        self.indexes = np.arange(len(self.list_images))\n",
        "        if self.shuffle == True:\n",
        "            np.random.shuffle(self.indexes)\n",
        "\n",
        "    def __data_generation(self, list_images_temp):\n",
        "        # X : (n_samples, *dim, n_channels)\n",
        "        'Generates data containing batch_size samples'\n",
        "        # Initialization\n",
        "        #X = np.empty((self.batch_size, *self.dim, self.n_channels))\n",
        "        #y = np.empty((self.batch_size), dtype=int)\n",
        "        X = [0] * self.batch_size\n",
        "        y = [0] * self.batch_size\n",
        "        # Generate data\n",
        "        for i, images in enumerate(list_images_temp):\n",
        "            # Store sample\n",
        "            X[i] = self.__image_processing(images[0])\n",
        "            # Store class\n",
        "            y[i] = self.__get_label_from_aid(images[1])\n",
        "        \n",
        "        X = np.asarray(X)\n",
        "        y = np.asarray(y)\n",
        "        return X, y\n",
        "\n",
        "    def __len__(self):\n",
        "        'Denotes the number of batches per epoch'\n",
        "        return int(np.floor(len(self.list_images) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        'Generate one batch of data'\n",
        "        # Generate indexes of the batch\n",
        "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
        "\n",
        "        # Find list of images\n",
        "        list_images_temp = [self.list_images[k] for k in indexes]\n",
        "\n",
        "        # Generate data\n",
        "        X, y = self.__data_generation(list_images_temp)\n",
        "\n",
        "        return X, y\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "wbtWXZqMaSzf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_label_from_aid(aid):\n",
        "    aid = aid.replace('a', '')\n",
        "    try:\n",
        "        index = trainOnlyFilesNames.index(str(aid) + \".wav\")\n",
        "        return trainLabels[index]\n",
        "    except:\n",
        "        pass\n",
        "    try:\n",
        "        index = validationOnlyFilesNames.index(str(aid) + \".wav\")\n",
        "        return validationLabels[index]\n",
        "    except:\n",
        "        pass\n",
        "    return -1\n",
        "\n",
        "def preproces_images(images):\n",
        "    newImages = [img_to_array(x) for x in images]\n",
        "    return newImages\n",
        "\n",
        "def generate_data_and_labels(data):\n",
        "    images, fileNames = data\n",
        "    \n",
        "    X = preproces_images(images)\n",
        "    Y = [get_label_from_aid(x) for x in fileNames]\n",
        "    \n",
        "    return X, Y\n",
        "\n",
        "def generate_labels(data):\n",
        "    images, fileNames = data\n",
        "    \n",
        "    Y = [get_label_from_aid(x) for x in fileNames]\n",
        "    \n",
        "    return Y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "PZen8pBGaSzi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# X_train, Y_train = generate_data_and_labels(train_fold_spectogram)\n",
        "# X_validation, Y_validation = generate_data_and_labels(validation_fold_spectogram)\n",
        "\n",
        "# X_train = np.asarray(X_train)\n",
        "# X_validation = np.asarray(X_validation)\n",
        "\n",
        "# Y_train = np.asarray(Y_train)\n",
        "# Y_validation = np.asarray(Y_validation)\n",
        "# X_test = np.array(generate_data_and_labels(test_fold_spectogram)[0])\n",
        "\n",
        "# del train_fold_spectogram\n",
        "# del validation_fold_spectogram\n",
        "# gc.collect()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "6J0lMAsNaSzm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_validation, Y_validation = generate_data_and_labels(validation_fold_spectogram)\n",
        "X_test = np.array(generate_data_and_labels(test_fold_spectogram)[0])\n",
        "X_validation = np.asarray(X_validation)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "PtI0_nhCaSzp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y_train = generate_labels(train_fold_spectogram)\n",
        "Y_train = np.asarray(Y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ACtIsdgVLlG0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "efa6150c-692e-4d38-c8a5-e3efe96bb205"
      },
      "source": [
        "print(np.unique(Y_train, return_counts=True))\n",
        "print(np.unique(Y_validation, return_counts=True))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(array([0, 1]), array([3476, 3524]))\n",
            "(array([0, 1]), array([ 920, 1080]))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "1mK3jZoXaSzu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_generator = DataGenerator(train_fold_spectogram)\n",
        "validation_generator = DataGenerator(validation_fold_spectogram)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Lge960kCaSz0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, InputLayer, LSTM, Bidirectional, GlobalMaxPooling1D, Conv2D, Dropout, MaxPooling2D,Input,ThresholdedReLU, Flatten, BatchNormalization, Activation, GlobalMaxPooling2D, concatenate, GlobalAveragePooling2D, AveragePooling2D, MaxPool2D\n",
        "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, CSVLogger, Callback, EarlyStopping\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, CSVLogger, Callback, EarlyStopping\n",
        "import sklearn\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "tqxOdyejaSz2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "main_input = Input(shape = (221, 223, 1))\n",
        "x = Conv2D(32, (3, 3), kernel_initializer='he_uniform', padding='same')(main_input)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation(\"relu\")(x)\n",
        "x = Conv2D(32, (3, 3), kernel_initializer='he_uniform', padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation(\"relu\")(x)\n",
        "x = Conv2D(32, (3, 3), kernel_initializer='he_uniform', padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation(\"relu\")(x)\n",
        "x = MaxPooling2D((2,2))(x)\n",
        "\n",
        "x = Conv2D(64, (3, 3), kernel_initializer='he_uniform', padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation(\"relu\")(x)\n",
        "x = Conv2D(64, (3, 3), kernel_initializer='he_uniform', padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation(\"relu\")(x)\n",
        "x = Conv2D(64, (3, 3), kernel_initializer='he_uniform', padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation(\"relu\")(x)\n",
        "x = MaxPooling2D((3,3))(x)\n",
        "\n",
        "x = Conv2D(128, (3, 3), kernel_initializer='he_uniform', padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation(\"relu\")(x)\n",
        "x = Conv2D(128, (3, 3), kernel_initializer='he_uniform', padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation(\"relu\")(x)\n",
        "x = Conv2D(128, (3, 3), kernel_initializer='he_uniform', padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation(\"relu\")(x)\n",
        "x = MaxPooling2D((2,2))(x)\n",
        "x = Flatten()(x)\n",
        "\n",
        "x = Dense(128, activation='relu', kernel_initializer='he_uniform')(x)\n",
        "x = Dense(64, activation='relu', kernel_initializer='he_uniform')(x)\n",
        "output = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "model = Model(inputs=main_input, outputs=output)\n",
        "model.compile(optimizer=\"adam\", loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "ao2d1c_aaSz6",
        "colab_type": "code",
        "outputId": "ff40c729-42e8-4e98-cb97-e2b433e196da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 748
        }
      },
      "source": [
        "#model.fit(X_train, Y_train, epochs = 50, validation_data= (X_validation, Y_validation),  batch_size = 32)\n",
        "class_weight = sklearn.utils.class_weight.compute_class_weight('balanced',np.unique(Y_train), Y_train)\n",
        "class_weight = {i : class_weight[i] for i in range(2)}\n",
        "\n",
        "mcp_save = ModelCheckpoint('model.hdf5', save_best_only=True, monitor='val_loss', mode='min')\n",
        "\n",
        "model.fit(x = train_generator, epochs = 200, validation_data=validation_generator, shuffle=True,\n",
        "                         class_weight = class_weight, \n",
        "                callbacks= [\n",
        "                              EarlyStopping(patience=10, monitor='val_loss', mode='min'),\n",
        "                              mcp_save,\n",
        "                              ReduceLROnPlateau(factor=.3)\n",
        "                         ])"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "218/218 [==============================] - 29s 134ms/step - loss: 1.3302 - accuracy: 0.5235 - val_loss: 0.9561 - val_accuracy: 0.5146 - lr: 0.0010\n",
            "Epoch 2/200\n",
            "218/218 [==============================] - 29s 133ms/step - loss: 0.7626 - accuracy: 0.5434 - val_loss: 0.7747 - val_accuracy: 0.5610 - lr: 0.0010\n",
            "Epoch 3/200\n",
            "218/218 [==============================] - 29s 134ms/step - loss: 0.6735 - accuracy: 0.5981 - val_loss: 0.6497 - val_accuracy: 0.6058 - lr: 0.0010\n",
            "Epoch 4/200\n",
            "218/218 [==============================] - 29s 133ms/step - loss: 0.6458 - accuracy: 0.6272 - val_loss: 0.6197 - val_accuracy: 0.6512 - lr: 0.0010\n",
            "Epoch 5/200\n",
            "218/218 [==============================] - 29s 132ms/step - loss: 0.6142 - accuracy: 0.6624 - val_loss: 0.6702 - val_accuracy: 0.5907 - lr: 0.0010\n",
            "Epoch 6/200\n",
            "218/218 [==============================] - 29s 133ms/step - loss: 0.5876 - accuracy: 0.6843 - val_loss: 0.6037 - val_accuracy: 0.6643 - lr: 0.0010\n",
            "Epoch 7/200\n",
            "218/218 [==============================] - 29s 132ms/step - loss: 0.5707 - accuracy: 0.7020 - val_loss: 0.6682 - val_accuracy: 0.6300 - lr: 0.0010\n",
            "Epoch 8/200\n",
            "218/218 [==============================] - 29s 133ms/step - loss: 0.5455 - accuracy: 0.7218 - val_loss: 0.6011 - val_accuracy: 0.6825 - lr: 0.0010\n",
            "Epoch 9/200\n",
            "218/218 [==============================] - 29s 132ms/step - loss: 0.5084 - accuracy: 0.7486 - val_loss: 0.6067 - val_accuracy: 0.6905 - lr: 0.0010\n",
            "Epoch 10/200\n",
            "218/218 [==============================] - 29s 133ms/step - loss: 0.4910 - accuracy: 0.7562 - val_loss: 0.5846 - val_accuracy: 0.6925 - lr: 0.0010\n",
            "Epoch 11/200\n",
            "218/218 [==============================] - 29s 133ms/step - loss: 0.4578 - accuracy: 0.7867 - val_loss: 0.5798 - val_accuracy: 0.7016 - lr: 0.0010\n",
            "Epoch 12/200\n",
            "218/218 [==============================] - 29s 133ms/step - loss: 0.4242 - accuracy: 0.8000 - val_loss: 0.6651 - val_accuracy: 0.6815 - lr: 0.0010\n",
            "Epoch 13/200\n",
            "218/218 [==============================] - 29s 132ms/step - loss: 0.3914 - accuracy: 0.8234 - val_loss: 0.6203 - val_accuracy: 0.7077 - lr: 0.0010\n",
            "Epoch 14/200\n",
            "218/218 [==============================] - 29s 132ms/step - loss: 0.3752 - accuracy: 0.8277 - val_loss: 0.6325 - val_accuracy: 0.7142 - lr: 0.0010\n",
            "Epoch 15/200\n",
            "218/218 [==============================] - 29s 132ms/step - loss: 0.3179 - accuracy: 0.8597 - val_loss: 0.6634 - val_accuracy: 0.6976 - lr: 0.0010\n",
            "Epoch 16/200\n",
            "218/218 [==============================] - 29s 132ms/step - loss: 0.2616 - accuracy: 0.8878 - val_loss: 0.6843 - val_accuracy: 0.7117 - lr: 0.0010\n",
            "Epoch 17/200\n",
            "218/218 [==============================] - 29s 132ms/step - loss: 0.2805 - accuracy: 0.8792 - val_loss: 0.7027 - val_accuracy: 0.7087 - lr: 0.0010\n",
            "Epoch 18/200\n",
            "218/218 [==============================] - 29s 131ms/step - loss: 0.2073 - accuracy: 0.9137 - val_loss: 0.8282 - val_accuracy: 0.7188 - lr: 0.0010\n",
            "Epoch 19/200\n",
            "218/218 [==============================] - 29s 132ms/step - loss: 0.1520 - accuracy: 0.9395 - val_loss: 0.7817 - val_accuracy: 0.7213 - lr: 0.0010\n",
            "Epoch 20/200\n",
            "218/218 [==============================] - 29s 132ms/step - loss: 0.1170 - accuracy: 0.9571 - val_loss: 1.0194 - val_accuracy: 0.7137 - lr: 0.0010\n",
            "Epoch 21/200\n",
            "218/218 [==============================] - 29s 132ms/step - loss: 0.1096 - accuracy: 0.9558 - val_loss: 1.2977 - val_accuracy: 0.6749 - lr: 0.0010\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f33087b1748>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5gD_6O5_lwl7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "UOPFuTWdaSz-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.load_weights('model.hdf5')\n",
        "predictions = model.predict(X_test).round()\n",
        "finalPredictions = predictions"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "nrpS3lPsaS0A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c10d6ee2-5974-456a-e7ba-1417573420ef"
      },
      "source": [
        "validation_predictions = model.predict(X_validation).round()\n",
        "from sklearn.metrics import accuracy_score\n",
        "accuracy_score(Y_validation, validation_predictions)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.702"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ya4dO40zIxnG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "spSZIZd1HYxM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#CROSS VALIDATION"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "_-4UvBYIaS0D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# #full_data = np.concatenate((train_fold_spectogram, validation_fold_spectogram))\n",
        "# X_full = ([],[])\n",
        "\n",
        "# for i in range(len(train_fold_spectogram[1])):\n",
        "#   X_full[0].append(train_fold_spectogram[0][i])\n",
        "#   X_full[1].append(train_fold_spectogram[1][i])\n",
        "\n",
        "# for i in range(len(validation_fold_spectogram[1])):\n",
        "#   X_full[0].append(validation_fold_spectogram[0][i])\n",
        "#   X_full[1].append(validation_fold_spectogram[1][i])\n",
        "\n",
        "# #Y_full = np.concatenate((Y_train, Y_validation))\n",
        "# Y_full = []\n",
        "# for i in range(len(Y_train)):\n",
        "#   Y_full.append(Y_train[i])\n",
        "# for i in range(len(Y_validation)):\n",
        "#   Y_full.append(Y_validation[i])\n",
        "# print(str(len(Y_full)) + \" samples\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "vXKWFGH9aS0F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# def create_model():\n",
        "#     main_input = Input(shape = (221, 223, 1))\n",
        "#     x = Conv2D(32, (3, 3), kernel_initializer='he_uniform', padding='same')(main_input)\n",
        "#     x = BatchNormalization()(x)\n",
        "#     x = Activation(\"relu\")(x)\n",
        "#     x = Conv2D(32, (3, 3), kernel_initializer='he_uniform', padding='same')(x)\n",
        "#     x = BatchNormalization()(x)\n",
        "#     x = Activation(\"relu\")(x)\n",
        "#     x = Conv2D(32, (3, 3), kernel_initializer='he_uniform', padding='same')(x)\n",
        "#     x = BatchNormalization()(x)\n",
        "#     x = Activation(\"relu\")(x)\n",
        "#     x = MaxPooling2D((2,2))(x)\n",
        "\n",
        "#     x = Conv2D(64, (3, 3), kernel_initializer='he_uniform', padding='same')(x)\n",
        "#     x = BatchNormalization()(x)\n",
        "#     x = Activation(\"relu\")(x)\n",
        "#     x = Conv2D(64, (3, 3), kernel_initializer='he_uniform', padding='same')(x)\n",
        "#     x = BatchNormalization()(x)\n",
        "#     x = Activation(\"relu\")(x)\n",
        "#     x = Conv2D(64, (3, 3), kernel_initializer='he_uniform', padding='same')(x)\n",
        "#     x = BatchNormalization()(x)\n",
        "#     x = Activation(\"relu\")(x)\n",
        "#     x = MaxPooling2D((3,3))(x)\n",
        "\n",
        "#     x = Conv2D(128, (3, 3), kernel_initializer='he_uniform', padding='same')(x)\n",
        "#     x = BatchNormalization()(x)\n",
        "#     x = Activation(\"relu\")(x)\n",
        "#     x = Conv2D(128, (3, 3), kernel_initializer='he_uniform', padding='same')(x)\n",
        "#     x = BatchNormalization()(x)\n",
        "#     x = Activation(\"relu\")(x)\n",
        "#     x = Conv2D(128, (3, 3), kernel_initializer='he_uniform', padding='same')(x)\n",
        "#     x = BatchNormalization()(x)\n",
        "#     x = Activation(\"relu\")(x)\n",
        "#     x = MaxPooling2D((2,2))(x)\n",
        "#     x = Flatten()(x)\n",
        "\n",
        "#     x = Dense(128, activation='relu', kernel_initializer='he_uniform')(x)\n",
        "#     x = Dense(64, activation='relu', kernel_initializer='he_uniform')(x)\n",
        "#     output = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "#     model = Model(inputs=main_input, outputs=output)\n",
        "#     model.compile(optimizer=\"adam\", loss='binary_crossentropy', metrics=['accuracy'])\n",
        "#     return model\n",
        "\n",
        "# from sklearn.model_selection import KFold\n",
        "\n",
        "\n",
        "\n",
        "# curentFold = 0\n",
        "# kf = KFold(n_splits=10, shuffle = True, random_state = 42)\n",
        "# for train_index, test_index in kf.split(X_full[1]):\n",
        "#     print(\"Starting Fold \"+str(curentFold))\n",
        "#     curentFold += 1\n",
        "#     gc.collect()\n",
        "#     X_train_fold = ([], [])\n",
        "#     X_test_fold = ([], [])\n",
        "\n",
        "#     for index in train_index:\n",
        "#       X_train_fold[0].append(X_full[0][index])\n",
        "#       X_train_fold[1].append(X_full[1][index])\n",
        "#     for index in test_index:\n",
        "#       X_test_fold[0].append(X_full[0][index])\n",
        "#       X_test_fold[1].append(X_full[1][index])\n",
        "\n",
        "#     Y_train_fold = np.array([Y_full[x] for x in train_index])\n",
        "#     Y_test_fold = np.array([Y_full[x] for x in test_index])\n",
        "    \n",
        "#     train_generator = DataGenerator(X_train_fold)\n",
        "#     validation_generator = DataGenerator(X_test_fold)\n",
        "    \n",
        "#     class_weight = sklearn.utils.class_weight.compute_class_weight('balanced',np.unique(Y_train_fold), Y_train_fold)\n",
        "#     class_weight = {i : class_weight[i] for i in range(2)}\n",
        "\n",
        "#     model=create_model()\n",
        "#     mcp_save = ModelCheckpoint('modelfold'+str(curentFold)+'.hdf5', save_best_only=True, monitor='val_loss', mode='min')\n",
        "\n",
        "#     model.fit(x = train_generator, epochs = 200, validation_data=validation_generator, shuffle=True,\n",
        "#                          class_weight = class_weight, \n",
        "#                 callbacks= [\n",
        "#                               EarlyStopping(patience=10, monitor='val_loss', mode='min'),\n",
        "#                               mcp_save,\n",
        "#                               ReduceLROnPlateau(factor=.3)\n",
        "#                          ])\n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "eAVYZyoAaS0K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# validation_fold_spectogram = read_all_images_for(\"validation\", \"fold_spectogram\")\n",
        "# X_validation, Y_validation = generate_data_and_labels(validation_fold_spectogram)\n",
        "# X_validation = np.array(X_validation)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "_y25OOebaS0N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# predictions = []\n",
        "# model=create_model()\n",
        "# model.load_weights('modelfold1.hdf5')\n",
        "\n",
        "# for i in range(1,11):\n",
        "#     if i == 8 or i == 4:\n",
        "#         continue\n",
        "#     model.load_weights('modelfold'+str(i)+'.hdf5')\n",
        "#     predictions.append(model.predict(X_validation))\n",
        "# finalPredictions = np.average(predictions, axis = 0)\n",
        "# finalPredictions = finalPredictions.round()\n",
        "# from sklearn.metrics import accuracy_score\n",
        "# accuracy_score(Y_validation, finalPredictions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "YYCPUIphaS0R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# predictions = []\n",
        "# model=create_model()\n",
        "# model.load_weights('modelfold1.hdf5')\n",
        "\n",
        "# for i in range(1,11):\n",
        "#     if i == 8 or i == 4:\n",
        "#         continue\n",
        "#     model.load_weights('modelfold'+str(i)+'.hdf5')\n",
        "#     predictions.append(model.predict(X_test))\n",
        "# finalPredictions = np.average(predictions, axis = 0)\n",
        "# finalPredictions = finalPredictions.round()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "vJXMUJ_7aS0U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_filenames = test_fold_spectogram[1]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "m55ECpv2aS0X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(\"submisie2kval.txt\", \"w+\") as f:\n",
        "    f.write(\"name,label\\n\")\n",
        "    for i in range(0, len(test_filenames)):\n",
        "        f.write(test_filenames[i] + \".wav,\" + str(int(finalPredictions[i][0]))+\"\\n\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "OW01xfBjaS0c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "HkDg5v6maS0j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zaopYzfJ2Ldi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}